# DLP (Deep Learning Phenotyper) package  
---
The DLP package phenotypes morphological variation of vertebrates using deep learning and CT scan image datasets. The model uses pre-trained Resnet50 along with a tunable Fully Connected (FC) layer and a linear SVM that can be customised based on the application at hand. This README file briefly introduces the scripts and how they can be used. For a more comprehensive guideline, please see the comments in each of the scripts.

## Repository content
Description of the directories in these repositories are provided below:

1. **association study scripts** - This directory contains Shell, R, and Matlab scripts that were used to run and process outputs of Genome-Wide Association Studies (GWAS).  
2. **labelling** - This directory contains a tutorial video and further documentation on how labelling of CT datasets should be done before the DLP package can be used.  
3. **scripts** - This directory contains all the Matlab scripts that were implemented to 1. pre-process 2. classify and 3. segment the CT image datasets in order to generate measurements that can quantify the morphology. The scripts directory itself branches to three sub-directories each containing scripts for the tasks mentioned above. **Note that Matlab scripts with an _ are functions that are called in scripts**. 

## How to install the DLP package 

The DLP package can be easily installed by just cloning the repository onto your local host. You can run the following command to clone this repository in the current directory of your local computer: 

	 git clone https://github.com/armankarshenas/dlp


## How to use the DLP package 

Most CT image datasets are generated as stacks of two-dimensional images in the Anterior-Posterior (AP) axis of the body and are commonly encoded as 16-bit wide TIFF images. These image stacks are often too large to be loaded on the RAM as three-dimensional tensors and create substantial memory constraints. Here, we, therefore, have implemented scripts that can be used to compress and denoise the images while keeping the information content intact. The deep learning models trained and used are also based on two-dimensional projections in order to minimise computational complexity and prevent overfitting. 

Each of the following scripts starts with a specification section that should be edited in order for the package to have the correct paths to image datasets and the metadata. 

### Preprocessing 
---
Please use the following scripts to pre-process the images as needed before training the network: 

1. To compress the images please run the following scripts in the order they have been represented here. The first script generates a bit profile that can be used by the second script to decide the number of bits that can be truncated. 
		
		Randomness.m
		Compress.m
2. The following scripts can be used to align the centre of images, rotate them, converts TIFFs to JPEGs, reverse the order of images in the image stack, and downsample images using a tunable Gaussian kernel respectively. 

		Centre.m
		Rotate.m
		JPEGCovert.m
		ReverseOrder.m
		Downsample.m
3. Once images are pre-processed, the following script should be used to generate image stacks in the other two projections: namely Left-Rigth (LR) and Dorsal-Ventral (DV). 

		Orientation.m
		
### Resnet50-based model training 
---

In order to train different models based on the feature space generated by the pre-trained network **Resnet50**, please run the following scripts in the order specified below: 

1. Label images based on the major feature that they contain (e.g if images 100-200 in the image stack contain the eye in the AP projection, move all of them into a directory called "eye"). Move all the directories with different labels to a single directory - this would be the path that needs to be provided to the scripts for the training data. 
2. Run the following script in order to find the optimal pooling layer for feature space generation. The script plots accuracy as a function of layer number and would allow you to find the optimal pooling layer in the Resnet50 structure. The default layer is the final average pooling layer of the network. 

		LayerValidation.m
3. Once the optimal pooling layer is found, please run the first script if you want to train a Fully Connected (FC) network using the feature space generated by the Resnet50 network, or the second script if you want to train a linear SVM model. 
		
		TrainFC.m
		TrainSVM.m
4. Once the models are trained and tested on the labelled dataset, unseen data should be prepared and fed into the classifier in order to generate projection profiles that will later be used to measure dimensions of features in all three dimensions. The following script can be used to feedforward the unseen data into the trained model: 

		SVMFeedForward.m
5. The labels for each image can now be used to generate measurements based on the features that they each contain. The measurements are done using many functions that are denoted by an "_" in their name. By running the following script, however, the measurements are generated and saved as an excel and txt file. 

		VoxelCorrection.m
### Semantic segmentation 
--- 

Many network structures have been developed in the past few years that can be used to segment or parse the image to sub-domains that are labelled. The process of labelling images to train a segmentation network is much more intensive, however, which is why only scripts for this were implemented but segmentation was not used on the cichlid data set. The two scripts below train two different segmentation architectures namely: U-net and Deeplabv3+ respectively.

		SemanticUNet.m
		SemanticDeepLabv3+.m 